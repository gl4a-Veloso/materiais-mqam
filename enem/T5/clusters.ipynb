{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f9235d",
   "metadata": {},
   "source": [
    "Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd55a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, cut_tree, cophenet\n",
    "from scipy.stats import zscore\n",
    "from scipy.linalg import eigh\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3df85",
   "metadata": {},
   "source": [
    "Funções para importação do base de dados e seleção as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfa5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_ENEM_CSV = \"PATH_TO_ENEM_2023.csv\"  # <- coloque o CSV aqui\n",
    "\n",
    "def load_and_preview(path):\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Dimensões:\", df.shape)\n",
    "    print(\"Colunas:\", df.columns.tolist())\n",
    "    display(df.head())\n",
    "    return df\n",
    "\n",
    "def select_variables(df:pd.DataFrame, vars_list:list[str]):\n",
    "    \"\"\"\n",
    "    Escolha as variáveis que farão parte da 'variável estatística de agrupamento'.\n",
    "    (Conforme o material: selecionar variáveis relevantes; a análise é sensível a isso). :contentReference[oaicite:17]{index=17}\n",
    "    \"\"\"\n",
    "    return df[vars_list].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40302f",
   "metadata": {},
   "source": [
    "Detecção de outliers multivariados (Mahalanobis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f59032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(X):\n",
    "    \"\"\"\n",
    "    Calcula D^2 de Mahalanobis para cada observação.\n",
    "    Usado nos materiais para identificar potenciais outliers multivariados. :contentReference[oaicite:18]{index=18}\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    mu = X.mean(axis=0)\n",
    "    cov = np.cov(X, rowvar=False)\n",
    "    cov_inv = linalg.pinv(cov)\n",
    "    dif = X - mu\n",
    "    left = np.dot(dif, cov_inv)\n",
    "    md2 = np.einsum('ij,ij->i', left, dif)\n",
    "    return md2\n",
    "\n",
    "def flag_outliers_md2(X, alpha=0.001):\n",
    "    \"\"\"\n",
    "    alpha: nível para marcar outliers (usando quão grande é D2).\n",
    "    Podemos usar um critério empírico (p-quantil) ou comparação com qui²(p).\n",
    "    Aqui retornamos os índices ordenados por D2 decrescente.\n",
    "    \"\"\"\n",
    "    md2 = mahalanobis_distance(X)\n",
    "    df_indices = np.argsort(md2)[::-1]\n",
    "    return md2, df_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1f2c7",
   "metadata": {},
   "source": [
    "Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_df(df:pd.DataFrame, method=\"zscore\"):\n",
    "    \"\"\"\n",
    "    O material recomenda z-score quando há diferentes dispersões. :contentReference[oaicite:19]{index=19}\n",
    "    \"\"\"\n",
    "    if method == \"zscore\":\n",
    "        scaler = StandardScaler()\n",
    "        arr = scaler.fit_transform(df.values)\n",
    "        df_s = pd.DataFrame(arr, index=df.index, columns=df.columns)\n",
    "        return df_s, scaler\n",
    "    else:\n",
    "        raise ValueError(\"Método de padronização não implementado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327686b2",
   "metadata": {},
   "source": [
    "Análise hierárquica (dendrograma) + cophenetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77222365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_analysis(X, method=\"ward\", metric=\"euclidean\", plot=True):\n",
    "    d = pdist(X, metric=metric)\n",
    "    Z = linkage(d, method=method)\n",
    "    c, coph_dists = cophenet(Z, d)  # coeficiente cofenético para avaliar dendrograma.\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        dendrogram(Z, truncate_mode='level', p=30)\n",
    "        plt.title(f\"Dendrograma (method={method}) — coef cofenético={c:.3f}\")\n",
    "        plt.xlabel(\"Observações\")\n",
    "        plt.ylabel(\"Distância\")\n",
    "        plt.show()\n",
    "    return Z, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37193205",
   "metadata": {},
   "source": [
    "Extrair sementes a partir do corte do dendrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfded9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeds_from_hierarchical(Z, X, k):\n",
    "    \"\"\"\n",
    "    Corta o dendrograma em k grupos e retorna os centróides como seeds para kmeans.\n",
    "    Recomendado combinar hierárquico -> k-means (slides). :contentReference[oaicite:22]{index=22}\n",
    "    \"\"\"\n",
    "    labels = cut_tree(Z, n_clusters=k).reshape(-1)\n",
    "    seeds = []\n",
    "    for lab in np.unique(labels):\n",
    "        seeds.append(X[labels == lab].mean(axis=0))\n",
    "    seeds = np.vstack(seeds)\n",
    "    return seeds, labels\n",
    "\n",
    "# ==========================\n",
    "# 8) K-means (com avaliação em K)\n",
    "# ==========================\n",
    "def kmeans_range(X, ks=range(2,8), seeds=None, n_init=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Testa vários k, retorna: inertia, silhouette para cada k.\n",
    "    (Material recomenda testar intervalo de k e avaliar). :contentReference[oaicite:23]{index=23}\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for k in ks:\n",
    "        if seeds is not None and seeds.shape[0] == k:\n",
    "            init = seeds\n",
    "            km = KMeans(n_clusters=k, init=init, n_init=1, random_state=random_state, max_iter=300)\n",
    "        else:\n",
    "            km = KMeans(n_clusters=k, n_init=n_init, random_state=random_state, max_iter=300)\n",
    "        labels = km.fit_predict(X)\n",
    "        inertia = km.inertia_\n",
    "        sil = silhouette_score(X, labels) if k > 1 else np.nan\n",
    "        results.append({'k': k, 'inertia': inertia, 'silhouette': sil, 'model': km, 'labels': labels})\n",
    "    return results\n",
    "\n",
    "def plot_k_diagnostics(results):\n",
    "    ks = [r['k'] for r in results]\n",
    "    inertias = [r['inertia'] for r in results]\n",
    "    sils = [r['silhouette'] for r in results]\n",
    "    fig, ax1 = plt.subplots(figsize=(9,4))\n",
    "    ax1.plot(ks, inertias, '-o', label='Inertia (WGSS)')\n",
    "    ax1.set_xlabel(\"k\")\n",
    "    ax1.set_ylabel(\"Inertia\")\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(ks, sils, '-s', color='tab:orange', label='Silhouette')\n",
    "    ax2.set_ylabel(\"Silhouette score\")\n",
    "    ax1.set_xticks(ks)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_title(\"Elbow (inertia) e Silhouette para seleção de k\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ==========================\n",
    "# 9) Perfil e interpretação\n",
    "# ==========================\n",
    "def cluster_profile(original_df:pd.DataFrame, cluster_labels):\n",
    "    \"\"\"\n",
    "    Para cada cluster: contar tamanho, média das variáveis originais, e ANOVA simples (ou descriptivo).\n",
    "    Material recomenda descrever centróides e interpretar características. :contentReference[oaicite:24]{index=24}\n",
    "    \"\"\"\n",
    "    df = original_df.copy()\n",
    "    df['cluster'] = cluster_labels\n",
    "    profile = df.groupby('cluster').agg(['count','mean','std'])\n",
    "    return profile\n",
    "\n",
    "def plot_cluster_profiles(df_vars, labels):\n",
    "    \"\"\"\n",
    "    Gráfico de perfis: médias padronizadas por cluster (útil para visualização). :contentReference[oaicite:25]{index=25}\n",
    "    \"\"\"\n",
    "    df_vars = pd.DataFrame(df_vars)\n",
    "    df_vars['cluster'] = labels\n",
    "    centroids = df_vars.groupby('cluster').mean()\n",
    "    centroids.T.plot(kind='line', marker='o', figsize=(10,5))\n",
    "    plt.title(\"Perfil dos clusters (médias das variáveis padronizadas)\")\n",
    "    plt.xlabel(\"Variáveis\")\n",
    "    plt.ylabel(\"Média (padronizada)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# ==========================\n",
    "# 10) Exemplo de execução sequencial\n",
    "# ==========================\n",
    "def run_full_pipeline(path, variables, hier_method=\"ward\", k_candidates=range(2,8)):\n",
    "    # 1) carregar\n",
    "    df_all = load_and_preview(path)\n",
    "    # 2) selecionar\n",
    "    df_vars = select_variables(df_all, variables)\n",
    "    # 4) outliers (Mahalanobis)\n",
    "    md2, idx_sorted = flag_outliers_md2(df_vars.values)\n",
    "    df_vars['MD2'] = md2\n",
    "    # mostra top 10 MD2 (potenciais outliers)\n",
    "    print(\"Top 10 potenciais outliers (Mahalanobis D^2):\")\n",
    "    display(df_vars.sort_values('MD2', ascending=False).head(10))\n",
    "    # nota: decidir remover ou não conforme contexto (material descreve que outliers podem formar clusters isolados). :contentReference[oaicite:26]{index=26}\n",
    "    # 5) padronizar\n",
    "    X_std, scaler = standardize_df(df_vars.drop(columns=['MD2']))\n",
    "    # 6) hierarquico\n",
    "    Z, coph = hierarchical_analysis(X_std.values, method=hier_method, plot=True)\n",
    "    print(\"Coeficiente cofenético:\", coph, \"(valores próximos a 0.8 são bons segundo material). :contentReference[oaicite:27]{index=27}\")\n",
    "    # 7) extrair seeds a partir de corte (escolha inicial k minimal, aqui pegamos a mediana de candidatos)\n",
    "    k0 = int(np.median(list(k_candidates)))\n",
    "    seeds, h_labels = seeds_from_hierarchical(Z, X_std.values, k=k0)\n",
    "    print(f\"Usando k0={k0} clusters para gerar seeds iniciais do hierárquico.\")\n",
    "    # 8) kmeans range (testar com e sem seeds)\n",
    "    results_no_seeds = kmeans_range(X_std.values, ks=k_candidates)\n",
    "    results_with_seeds = None\n",
    "    if seeds.shape[0] == k0:\n",
    "        # apenas ilustração: testamos seeds para k0\n",
    "        results_with_seeds = kmeans_range(X_std.values, ks=[k0], seeds=seeds)\n",
    "    # 9) plot diagnósticos\n",
    "    plot_k_diagnostics(results_no_seeds)\n",
    "    # 10) escolher melhor k (ex.: maior silhouette ou elbow)\n",
    "    best = max(results_no_seeds, key=lambda r: r['silhouette'] if not np.isnan(r['silhouette']) else -999)\n",
    "    print(\"Melhor k por silhouette:\", best['k'], \"silhouette:\", best['silhouette'])\n",
    "    # 11) perfil e plots\n",
    "    best_model = best['model']\n",
    "    labels = best['labels']\n",
    "    profile = cluster_profile(df_vars.drop(columns=['MD2']), labels)\n",
    "    display(profile)\n",
    "    plot_cluster_profiles(X_std, labels)\n",
    "    # PCA 2D plot com clusters\n",
    "    pca = PCA(n_components=2)\n",
    "    proj = pca.fit_transform(X_std)\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.scatterplot(x=proj[:,0], y=proj[:,1], hue=labels, palette='tab10', s=40)\n",
    "    plt.title(f\"PCA 2D com clusters (k={best['k']})\")\n",
    "    plt.show()\n",
    "    return {\n",
    "        'df_vars': df_vars,\n",
    "        'scaler': scaler,\n",
    "        'hier_linkage': Z,\n",
    "        'cofenetic': coph,\n",
    "        'kmeans_results': results_no_seeds,\n",
    "        'best': best\n",
    "    }\n",
    "\n",
    "# ==========================\n",
    "# 11) Uso: ajustar variáveis conforme seu dataset ENEM\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    # exemplo: variáveis de nota (ajuste para o nome real no CSV)\n",
    "    vars_to_use = ['nota_mat', 'nota_por', 'nota_nat', 'nota_hum', 'nota_redacao']\n",
    "    # Rode o pipeline (trocando PATH_TO_ENEM_CSV no topo)\n",
    "    out = run_full_pipeline(PATH_TO_ENEM_CSV, vars_to_use, missing_strategy=\"drop\", hier_method=\"ward\", k_candidates=range(2,9))\n",
    "    # Salve labels no arquivo original (exemplo)\n",
    "    best_labels = out['best']['labels']\n",
    "    df_in = pd.read_csv(PATH_TO_ENEM_CSV)\n",
    "    df_in = df_in.loc[out['df_clean'].index]  # manter mesma ordem/índices limpos\n",
    "    df_in['cluster'] = best_labels\n",
    "    df_in.to_csv(\"enem_2023_clusters.csv\", index=False)\n",
    "    print(\"Clusters salvos em enem_2023_clusters.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
