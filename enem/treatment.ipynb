{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bff5458",
   "metadata": {},
   "source": [
    "Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7de340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b477a",
   "metadata": {},
   "source": [
    "Importar base de dados original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e52197",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"databases/MICRODADOS_ENEM_2023.csv\" # 1.735 GB (Excluído)\n",
    "try:\n",
    "    df = pd.read_csv(path, sep=\";\", encoding=\"latin-1\", low_memory=False)\n",
    "    display(df) # 3933955 rows × 76 columns (3m 19.3s)\n",
    "except:\n",
    "    print(f\"Arquivo {path} não encontrado.\")\n",
    "    df = pd.read_csv(\"databases/ENEM_2023_SP_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b6366",
   "metadata": {},
   "source": [
    "Filtrando estudantes da cidade de São Paulo, que não são treineros e não faltaram ou foram eliminados em nenhuma prova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sp_students(df:pd.DataFrame):\n",
    "    filter = (\n",
    "        (df[\"NO_MUNICIPIO_ESC\"] == \"São Paulo\") & # Estudou na cidade de São Paulo \n",
    "        (df[\"IN_TREINEIRO\"] == 0) &               # Não é treineiro\n",
    "        (df[\"TP_PRESENCA_CH\"] == 1) &             # Não faltou, nem foi eliminado da prova\n",
    "        (df[\"TP_PRESENCA_CN\"] == 1) &             # Não faltou, nem foi eliminado da prova\n",
    "        (df[\"TP_PRESENCA_LC\"] == 1) &             # Não faltou, nem foi eliminado da prova\n",
    "        (df[\"TP_PRESENCA_MT\"] == 1)               # Não faltou, nem foi eliminado da prova\n",
    "    )\n",
    "    return df[filter]\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_1.csv\")\n",
    "df = filter_sp_students(df) \n",
    "df.to_csv(\"databases/ENEM_2023_SP_1.csv\", index=False)\n",
    "\n",
    "display(df) # 35416 rows × 76 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b55ff",
   "metadata": {},
   "source": [
    "Excluindo colunas \"desnecessárias\", mas mantendo aquelas que serão utilizadas para calcular outros campos. Também feita a renomeação de algumas colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28daf817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(df:pd.DataFrame):\n",
    "    cols = [\"TP_FAIXA_ETARIA\", \"TP_SEXO\", \"TP_COR_RACA\", \"TP_ENSINO\", \"TP_DEPENDENCIA_ADM_ESC\", \"NU_NOTA_CH\", \"NU_NOTA_CN\", \"NU_NOTA_MT\", \"NU_NOTA_LC\", \"NU_NOTA_REDACAO\", \"Q001\", \"Q002\", \"Q005\", \"Q006\", \"Q010\", \"Q011\", \"Q012\", \"Q013\", \"Q014\", \"Q015\", \"Q016\", \"Q017\", \"Q019\", \"Q022\", \"Q024\", \"Q025\",]\n",
    "    df = df[cols]\n",
    "\n",
    "    rename_dict = {\n",
    "        \"Q001\": \"ESCOLARIDADE_PAI\",\n",
    "        \"Q002\": \"ESCOLARIDADE_MAE\",\n",
    "        \"Q005\": \"N_PESSOAS_CASA\",\n",
    "        \"Q006\": \"RENDA_MENSAL_CASA\",\n",
    "        \"Q010\": \"N_CARRO_CASA\",\n",
    "        \"Q011\": \"N_MOTO_CASA\",\n",
    "\n",
    "        \"Q012\": \"N_GELADEIRA_CASA\",\n",
    "        \"Q013\": \"N_FREEZER_CASA\",\n",
    "        \"Q014\": \"N_LAVA_ROUPA_CASA\",\n",
    "        \"Q015\": \"N_SECA_ROUPA_CASA\",\n",
    "        \"Q016\": \"N_MICROONDAS_CASA\",\n",
    "        \"Q017\": \"N_LAVA_LOUCA_CASA\",\n",
    "        \"Q019\": \"N_TV_CASA\",\n",
    "\n",
    "        \"Q022\": \"N_CELULAR_CASA\",\n",
    "        \"Q024\": \"N_COMP_CASA\",\n",
    "        \"Q025\": \"INTERNET_CASA\"\n",
    "    }\n",
    "\n",
    "    return df.rename(columns=rename_dict)\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_1.csv\")\n",
    "df = filter_columns(df)\n",
    "df.to_csv(\"databases/ENEM_2023_SP_2.csv\", index=False)\n",
    "\n",
    "display(df) # 35416 rows × 26 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff92e445",
   "metadata": {},
   "source": [
    "Sequência de value counts para observar proporções de certas categorias na amostra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_value_counts(df:pd.DataFrame):\n",
    "    categoric_cols = [\"TP_FAIXA_ETARIA\", \"TP_SEXO\", \"TP_COR_RACA\", \"TP_ENSINO\", \"TP_DEPENDENCIA_ADM_ESC\", \"ESCOLARIDADE_PAI\", \"ESCOLARIDADE_MAE\", \"N_PESSOAS_CASA\", \"RENDA_MENSAL_CASA\", \"N_GELADEIRA_CASA\", \"N_FREEZER_CASA\", \"N_LAVA_ROUPA_CASA\", \"N_SECA_ROUPA_CASA\", \"N_MICROONDAS_CASA\", \"N_LAVA_LOUCA_CASA\", \"N_TV_CASA\", \"N_CARRO_CASA\", \"N_MOTO_CASA\", \"N_CELULAR_CASA\", \"N_COMP_CASA\", \"INTERNET_CASA\"]\n",
    "    for col in categoric_cols:\n",
    "        print(col)\n",
    "        vc_df = df[col].value_counts(dropna=False).reset_index()\n",
    "        vc_df.columns = ['VALOR', 'FREQUENCIA']\n",
    "        display(vc_df)\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_2.csv\")\n",
    "all_value_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c488735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_not_available_data(df:pd.DataFrame):\n",
    "    filter = (\n",
    "        (df[\"TP_COR_RACA\"] == 0) |\n",
    "        (df[\"TP_COR_RACA\"] == 6) |\n",
    "        (df[\"TP_ENSINO\"] != 1.0) |\n",
    "        (df[\"ESCOLARIDADE_MAE\"] == \"H\") | \n",
    "        (df[\"ESCOLARIDADE_PAI\"] == \"H\")\n",
    "    )\n",
    "\n",
    "    df = df.drop(columns=[\"TP_ENSINO\"])\n",
    "    return df.loc[~filter].reset_index(drop=True)\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_2.csv\")\n",
    "df = drop_not_available_data(df)\n",
    "df.to_csv(\"databases/ENEM_2023_SP_3.csv\", index=False)\n",
    "\n",
    "display(df) # 31731 rows × 25 columns (3703 linhas escluídas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b77ffc",
   "metadata": {},
   "source": [
    "Obtendo colunas de estimação para renda, faixa etária, além de outra para indicar a estimativa de carros, eletrodomésticos, computadores e celular por pessoa da família."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimative_and_simplified_columns(df:pd.DataFrame):\n",
    "    map_renda = {\n",
    "        \"A\": 0,                       # Nenhuma renda\n",
    "        \"B\": (0 + 1320)/2,            # Até 1320 (médio = 660)\n",
    "        \"C\": (1320.01 + 1980)/2,      # 1650\n",
    "        \"D\": (1980.01 + 2640)/2,      # 2310\n",
    "        \"E\": (2640.01 + 3300)/2,      # 2970\n",
    "        \"F\": (3300.01 + 3960)/2,      # 3630\n",
    "        \"G\": (3960.01 + 5280)/2,      # 4620\n",
    "        \"H\": (5280.01 + 6600)/2,      # 5940\n",
    "        \"I\": (6600.01 + 7920)/2,      # 7260\n",
    "        \"J\": (7920.01 + 9240)/2,      # 8580\n",
    "        \"K\": (9240.01 + 10560)/2,     # 9900\n",
    "        \"L\": (10560.01 + 11880)/2,    # 11220\n",
    "        \"M\": (11880.01 + 13200)/2,    # 12540\n",
    "        \"N\": (13200.01 + 15840)/2,    # 14520\n",
    "        \"O\": (15840.01 + 19800)/2,    # 17820\n",
    "        \"P\": (19800.01 + 26400)/2,    # 23100\n",
    "        \"Q\": (26400.01 + 33000)/2     # Arbitrário, assume R$ 33000 pois é a mesma distância do intervalo anterior\n",
    "    }\n",
    "    map_idade = {\n",
    "        1: 16,               # Menor de 17 anos -> assume 16\n",
    "        2: 17,\n",
    "        3: 18,\n",
    "        4: 19,\n",
    "        5: 20,\n",
    "        6: 21,\n",
    "        7: 22,\n",
    "        8: 23,\n",
    "        9: 24,\n",
    "        10: 25,\n",
    "        11: (26 + 30)/2,   # 28\n",
    "        12: (31 + 35)/2,   # 33\n",
    "        13: (36 + 40)/2,   # 38\n",
    "        14: (41 + 45)/2,   # 43\n",
    "        15: (46 + 50)/2,   # 48\n",
    "        16: (51 + 55)/2,   # 53\n",
    "        17: (56 + 60)/2,   # 58\n",
    "        18: (61 + 65)/2,   # 63\n",
    "        19: (66 + 70)/2,   # 68\n",
    "        20: (71 + 75)/2    # Maior de 70 anos\n",
    "    }\n",
    "    map_quant = {\n",
    "        \"A\": 0,\n",
    "        \"B\": 1,\n",
    "        \"C\": 2,\n",
    "        \"D\": 3,\n",
    "        \"E\": 4.5\n",
    "    }\n",
    "    cols_to_map = [\"N_CELULAR_CASA\", \"N_COMP_CASA\", \"N_CARRO_CASA\", \"N_MOTO_CASA\", \"N_GELADEIRA_CASA\", \"N_FREEZER_CASA\", \"N_LAVA_ROUPA_CASA\", \"N_SECA_ROUPA_CASA\", \"N_MICROONDAS_CASA\", \"N_LAVA_LOUCA_CASA\", \"N_TV_CASA\"]\n",
    "\n",
    "    df[cols_to_map] = df[cols_to_map].apply(lambda x: x.map(map_quant))\n",
    "\n",
    "    df[\"EST_IDADE\"] = df[\"TP_FAIXA_ETARIA\"].map(map_idade)\n",
    "    df[\"EST_RENDA_PER_CAP\"] = (df[\"RENDA_MENSAL_CASA\"].map(map_renda))/df[\"N_PESSOAS_CASA\"]\n",
    "    df[\"EST_CELULAR_PER_CAP\"] = (df[\"N_CELULAR_CASA\"])/df[\"N_PESSOAS_CASA\"]\n",
    "    df[\"EST_COMP_PER_CAP\"] = (df[\"N_COMP_CASA\"])/df[\"N_PESSOAS_CASA\"]\n",
    "    df[\"EST_VEICULO_PER_CAP\"] = (df[[\"N_CARRO_CASA\", \"N_MOTO_CASA\"]].sum(axis=1))/df[\"N_PESSOAS_CASA\"]\n",
    "    df[\"EST_ELE_DOM_PER_CAP\"] = (df[[\"N_GELADEIRA_CASA\", \"N_FREEZER_CASA\", \"N_LAVA_ROUPA_CASA\", \"N_SECA_ROUPA_CASA\", \"N_MICROONDAS_CASA\", \"N_LAVA_LOUCA_CASA\", \"N_TV_CASA\"]].sum(axis=1))/df[\"N_PESSOAS_CASA\"]\n",
    "\n",
    "    df = df.drop(columns=cols_to_map)\n",
    "    df = df.drop(columns=[\"TP_FAIXA_ETARIA\", \"N_PESSOAS_CASA\", \"RENDA_MENSAL_CASA\"])\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_3.csv\")\n",
    "df = create_estimative_and_simplified_columns(df)\n",
    "df.to_csv(\"databases/ENEM_2023_SP_4.csv\", index=False)\n",
    "\n",
    "display(df) # 31731 rows × 17 columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685c698",
   "metadata": {},
   "source": [
    "Detectando e analisando outliers (usando o método Tukey/IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview_outliers_for_column(df:pd.DataFrame, col:str) -> dict:    \n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "\n",
    "    inf = Q1 - 1.5 * (Q3 - Q1)\n",
    "    sup = Q3 + 1.5 * (Q3 - Q1)\n",
    "    outliers_inf = df[df[col] < inf].shape[0]\n",
    "    outliers_sup = df[df[col] > sup].shape[0]\n",
    "\n",
    "    return {\n",
    "        \"COLUNA\": col,\n",
    "        \"LIMITE_INF\": inf,\n",
    "        \"LIMITE_SUP\": sup,\n",
    "        \"N_OUTLIERS_INF\": outliers_inf,\n",
    "        \"N_OUTLIERS_SUP\": outliers_sup,\n",
    "        \"TOTAL_OUTLIERS\": outliers_inf + outliers_sup\n",
    "    }\n",
    "\n",
    "def overview_outliers(df:pd.DataFrame):\n",
    "    cols = [\"NU_NOTA_CH\", \"NU_NOTA_CN\", \"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_REDACAO\", \"EST_IDADE\", \"EST_RENDA_PER_CAP\", \"EST_CELULAR_PER_CAP\", \"EST_COMP_PER_CAP\", \"EST_VEICULO_PER_CAP\", \"EST_ELE_DOM_PER_CAP\"]\n",
    "    results = [overview_outliers_for_column(df, col) for col in cols]\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_4.csv\")\n",
    "outliers = overview_outliers(df)\n",
    "\n",
    "display(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93d000",
   "metadata": {},
   "source": [
    "Comparando métricas dos outliers com a amostra total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(df:pd.DataFrame, col:str):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    inf = Q1 - 1.5 * (Q3 - Q1)\n",
    "    sup = Q3 + 1.5 * (Q3 - Q1)\n",
    "\n",
    "    return df[(df[col] < inf) | (df[col] > sup)]\n",
    "\n",
    "def get_no_outliers(df:pd.DataFrame, col:str):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    inf = Q1 - 1.5 * (Q3 - Q1)\n",
    "    sup = Q3 + 1.5 * (Q3 - Q1)\n",
    "\n",
    "    return df[(df[col] > inf) & (df[col] < sup)]\n",
    "\n",
    "def compare_outliers(df:pd.DataFrame, outliers_col:str, comp_col: str):\n",
    "    df_outliers = get_outliers(df, outliers_col)\n",
    "    df_no_outliers = get_no_outliers(df, outliers_col)\n",
    "    stats_df_no_outliers = {\n",
    "        \"Média\": df_no_outliers[comp_col].mean(),\n",
    "        \"Mediana\": df_no_outliers[comp_col].median(),\n",
    "        \"Variância\": df_no_outliers[comp_col].var(),\n",
    "        \"Desvio Padrão\": df_no_outliers[comp_col].std(),\n",
    "        \"Amplitude\": df_no_outliers[comp_col].max() - df_no_outliers[comp_col].min()\n",
    "    }\n",
    "    stats_df_outliets = {\n",
    "        \"Média\": df_outliers[comp_col].mean(),\n",
    "        \"Mediana\": df_outliers[comp_col].median(),\n",
    "        \"Variância\": df_outliers[comp_col].var(),\n",
    "        \"Desvio Padrão\": df_outliers[comp_col].std(),\n",
    "        \"Amplitude\": df_outliers[comp_col].max() - df_outliers[comp_col].min()\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame({\"NÃO OUTLIERS\": stats_df_no_outliers, \"OUTLIERS\": stats_df_outliets})\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_4.csv\")\n",
    "cols = [\"NU_NOTA_CH\", \"NU_NOTA_CN\", \"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_REDACAO\"]\n",
    "for col in cols:\n",
    "    print(col)\n",
    "    comp = compare_outliers(df, \"EST_IDADE\", col)\n",
    "    display(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc5ed6",
   "metadata": {},
   "source": [
    "Gerar recorte aleatório de 10000 linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a98f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(df:pd.DataFrame, sample_size:int):\n",
    "    return df.sample(sample_size)\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_4.csv\")\n",
    "sample = generate_sample(df, 10000)\n",
    "#sample.to_csv(\"databases/ENEM_2023_SP_5.csv\", index=False)\n",
    "\n",
    "display(sample) # 10000 rows x 17 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02c8413",
   "metadata": {},
   "source": [
    "Comparando recorte aleatório com sua amostra geradora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a391775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_numeric_col(df:pd.DataFrame, sample:pd.DataFrame, col:str):\n",
    "    stats_df = {\n",
    "        \"Média\": df[col].mean(),\n",
    "        \"Mediana\": df[col].median(),\n",
    "        \"Variância\": df[col].var(),\n",
    "        \"Desvio Padrão\": df[col].std(),\n",
    "    }\n",
    "    stats_sample = {\n",
    "        \"Média\": sample[col].mean(),\n",
    "        \"Mediana\": sample[col].median(),\n",
    "        \"Variância\": sample[col].var(),\n",
    "        \"Desvio Padrão\": sample[col].std(),\n",
    "    }\n",
    "\n",
    "    comp = pd.DataFrame({\"TUDO\": stats_df, \"AMOSTRA\": stats_sample})\n",
    "    comp[\"DESVIO\"] = (comp[\"AMOSTRA\"] - comp[\"TUDO\"])/comp[\"TUDO\"]\n",
    "    return comp\n",
    "\n",
    "def compare_categoric_cols(df:pd.DataFrame, sample:pd.DataFrame, col:str):\n",
    "    total_pct = df[col].value_counts(normalize=True)\n",
    "    sample_pct = sample[col].value_counts(normalize=True)\n",
    "    comp = pd.concat([total_pct, sample_pct], axis=1).fillna(0)\n",
    "\n",
    "    comp.columns = ['TUDO', 'AMOSTRA']\n",
    "    comp['DESVIO'] = (comp['AMOSTRA'] - comp['TUDO']) / comp['TUDO']\n",
    "\n",
    "    return comp\n",
    "\n",
    "def compare_sample(df:pd.DataFrame, sample:pd.DataFrame):\n",
    "    numeric_cols = [\"NU_NOTA_CH\", \"NU_NOTA_CN\", \"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_REDACAO\", \"EST_IDADE\", \"EST_RENDA_PER_CAP\", \"EST_VEICULO_PER_CAP\",\t\"EST_CELULAR_PER_CAP\", \"EST_COMP_PER_CAP\", \"EST_ELE_DOM_PER_CAP\"]\n",
    "    categoric_cols = [\"TP_SEXO\", \"TP_COR_RACA\",\t\"TP_DEPENDENCIA_ADM_ESC\", \"ESCOLARIDADE_PAI\",\t\"ESCOLARIDADE_MAE\",\t\"INTERNET_CASA\"]\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        print(col)\n",
    "        display(compare_numeric_col(df, sample, col))\n",
    "\n",
    "    for col in categoric_cols:\n",
    "        print(col)\n",
    "        display(compare_categoric_cols(df, sample, col))\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_4.csv\")\n",
    "sample = pd.read_csv(\"databases/ENEM_2023_SP_5.csv\")\n",
    "compare_sample(df, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba34cd",
   "metadata": {},
   "source": [
    "Alterando nome das categorias para torná-las mais descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_values(df:pd.DataFrame):\n",
    "    map_sexo = {\n",
    "        \"M\": \"Masculino\",\n",
    "        \"F\": \"Feminino\"\n",
    "    }\n",
    "    map_cor_raca = {\n",
    "        0: \"Nao declarado\",\n",
    "        1: \"Branca\",\n",
    "        2: \"Preta\",\n",
    "        3: \"Parda\",\n",
    "        4: \"Amarela\",\n",
    "        5: \"Indigena\",\n",
    "        6: \"Nao dispõe da informação\"\n",
    "    }\n",
    "    map_dependencia = {\n",
    "        1: \"Federal\",\n",
    "        2: \"Estadual\",\n",
    "        3: \"Municipal\",\n",
    "        4: \"Privada\"\n",
    "    }\n",
    "    map_escolaridade = {\n",
    "        \"A\": \"Nunca estudou\",\n",
    "        \"B\": \"EF-1 incompleto\",      # até 4ª série/5º ano\n",
    "        \"C\": \"EF-2 incompleto\",        # completou 4ª, não completou 8ª\n",
    "        \"D\": \"EM incompleto\",\n",
    "        \"E\": \"ES incompleto\",\n",
    "        \"F\": \"PG incompleto\",\n",
    "        \"G\": \"PG completo\",\n",
    "        \"H\": \"Indisponivel\"\n",
    "    }\n",
    "    map_internet = {\n",
    "        \"A\": False,\n",
    "        \"B\": True\n",
    "    }\n",
    "    \n",
    "    df[\"TP_SEXO\"] = df[\"TP_SEXO\"].map(map_sexo)\n",
    "    df[\"TP_COR_RACA\"] = df[\"TP_COR_RACA\"].map(map_cor_raca)\n",
    "    df[\"TP_DEPENDENCIA_ADM_ESC\"] = df[\"TP_DEPENDENCIA_ADM_ESC\"].map(map_dependencia)\n",
    "    df[\"ESCOLARIDADE_MAE\"] = df[\"ESCOLARIDADE_MAE\"].map(map_escolaridade)\n",
    "    df[\"ESCOLARIDADE_PAI\"] = df[\"ESCOLARIDADE_PAI\"].map(map_escolaridade)\n",
    "    df[\"INTERNET_CASA\"] = df[\"INTERNET_CASA\"].map(map_internet)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"databases/ENEM_2023_SP_5.csv\")\n",
    "df = rename_values(df)\n",
    "df.to_csv(\"databases/ENEM_2023_FINAL.csv\", index=False)\n",
    "\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
